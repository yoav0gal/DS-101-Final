{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Adding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hotels_file_path = \"./hotels_data.csv\"  \n",
    "df = pd.read_csv(hotels_file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add columns and load to new CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure dates are in correct format\n",
    "df['Snapshot Date'] = pd.to_datetime(df['Snapshot Date'])\n",
    "df['Checkin Date'] = pd.to_datetime(df['Checkin Date'])\n",
    "\n",
    "df['DayDiff'] = (df['Checkin Date'] - df['Snapshot Date']).dt.days\n",
    "df['WeekDay'] = df['Checkin Date'].dt.day_name()\n",
    "df['DiscountDiff'] = df['Original Price'] - df['Discount Price']\n",
    "df['DiscountPerc'] = (df['DiscountDiff'] / df['Original Price']) * 100\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_hotels_path = \"./hotels_data_changed.csv\"\n",
    "df.to_csv(changed_hotels_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Best Discount Code\n",
    "\n",
    "\n",
    "**b. Classification Algorithms:** \n",
    "   - After creating this dataset, we will implement various classification algorithms in Python to predict the maximum discount code given the input parameters. \n",
    "   - Implement and evaluate the following five algorithms: Random Forest, Decision Tree, NaÃ¯ve Bayes, XGBoost, and a simple Random classifier.\n",
    "   - For each algorithm, you need to experiment with different parameter settings to find the optimal combination that yields the best performance. \n",
    "   - Explanation of how each chosen parameter affects the algorithm's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "\n",
    "df = pd.read_csv(changed_hotels_path) \n",
    "df = df[['WeekDay', 'Snapshot Date', 'Checkin Date', 'DayDiff', 'Hotel Name', 'Discount Code']] \n",
    "df = df.rename(columns={'Discount Code': 'Class'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "def map_days_to_numbers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    weekday_mapping = {'Sunday': 1, 'Monday': 2, 'Tuesday': 3, 'Wednesday': 4, 'Thursday': 5, 'Friday': 6, 'Saturday': 7}\n",
    "    df['WeekDay'] = df['WeekDay'].map(weekday_mapping)\n",
    "    return df\n",
    "\n",
    "def map_hotel_names_to_numbers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    hotel_mapping = {hotel: i for i, hotel in enumerate(df['Hotel Name'].unique())}\n",
    "    df['Hotel_Index'] = df['Hotel Name'].map(hotel_mapping)\n",
    "    df.drop(['Hotel Name'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def map_date_to_numbers(df: pd.DataFrame, old_coloumn: str, new_coloumn: str) -> pd.DataFrame:\n",
    "    df[old_coloumn] = pd.to_datetime(df[old_coloumn])\n",
    "    df[f'{new_coloumn}_Year'] = df[old_coloumn].dt.year\n",
    "    df[f'{new_coloumn}_Month'] = df[old_coloumn].dt.month\n",
    "    df[f'{new_coloumn}_Day'] = df[old_coloumn].dt.day\n",
    "    df.drop([old_coloumn], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = map_days_to_numbers(df)\n",
    "df = map_hotel_names_to_numbers(df)\n",
    "df = map_date_to_numbers(df, 'Snapshot Date', 'Snapshot')\n",
    "df = map_date_to_numbers(df, 'Checkin Date', 'Checkin')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "numerical_features = ['DayDiff', 'Snapshot_Year', 'Snapshot_Month', 'Snapshot_Day', 'Checkin_Year', 'Checkin_Month', 'Checkin_Day']\n",
    "categorical_features = ['WeekDay', 'Hotel_Index']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for numerical features\n",
    "for i, feature in enumerate(numerical_features):\n",
    "  sns.histplot(data=df, x=feature, ax=axes[i])\n",
    "  axes[i].set_title(f'Distribution of {feature}')\n",
    "\n",
    "# Plot bar charts for categorical features (assuming enough data for each category)\n",
    "for i, feature in enumerate(categorical_features):\n",
    "  sns.countplot(data=df, x=feature, ax=axes[i])\n",
    "  axes[i].set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df[['WeekDay', 'DayDiff', 'Hotel_Index', 'Snapshot_Year', 'Snapshot_Month', 'Snapshot_Day', 'Checkin_Year', 'Checkin_Month', 'Checkin_Day']]\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "We have the following feature types:\n",
    "\n",
    "* **Continuous:**\n",
    "    - `DayDiff` \n",
    "    - `Snapshot_Year`\n",
    "    - `Snapshot_Month`\n",
    "    - `Snapshot_Day`\n",
    "    - `Checkin_Year`\n",
    "    - `Checkin_Month`\n",
    "    - `Checkin_Day`\n",
    "\n",
    "* **Categorical:**\n",
    "    - `WeekDay` \n",
    "    - `Hotel_Index`\n",
    "\n",
    "**Naive Bayes Variants and Suitability:**\n",
    "\n",
    "* **GaussianNB:**\n",
    "    - **Best suited for continuous features.** It assumes that the features are normally distributed (Gaussian). Since we have several continuous features GaussianNB seems like the choice.\n",
    "\n",
    "* **MultinomialNB:**\n",
    "    - **Suitable for discrete features.** While `WeekDay` and `Hotel_Index` can be treated as categorical, they don't inherently represent counts or frequencies.\n",
    "\n",
    "* **BernoulliNB:**\n",
    "    - **Suitable for binary features.** Not applicable in this case as none of the features are binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Clustering Based on Price Polices \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Identify the 150 hotels with the most data in the dataset and extract their records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"./hotels_data.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "hotel_counts = df['Hotel Name'].value_counts()\n",
    "top_150_hotels = hotel_counts.head(150).index\n",
    "filtered_df = df[df['Hotel Name'].isin(top_150_hotels)]\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 40 most common check-in dates  in the dataset and extract their records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_counts = filtered_df['Checkin Date'].value_counts()\n",
    "top_40_checkin_dates = checkin_counts.head(40).index\n",
    "filtered_checkin_df = filtered_df[filtered_df['Checkin Date'].isin(top_40_checkin_dates)]\n",
    "\n",
    "filtered_checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4 - Building a Predictive Model for Hotel Pricing Dynamics Using Snapshot Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5 - PySpark & Mllib for step 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-101-Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
