{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hotel Scraping project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hamamahome\\appdata\\roaming\\python\\python312\\site-packages (from webdriver_manager) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hamamahome\\anaconda3\\envs\\ds-101-final\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium beautifulsoup4 webdriver_manager requests lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "\n",
    "def build_url(time_to_travel: int, length_of_stay: int) -> str:\n",
    "    today = datetime.today()\n",
    "\n",
    "    checkin_date = today + timedelta(days=time_to_travel)\n",
    "    checkout_date = checkin_date + timedelta(days=length_of_stay)\n",
    "    checkin_date_str = checkin_date.strftime('%Y-%m-%d')\n",
    "    checkout_date_str = checkout_date.strftime('%Y-%m-%d')\n",
    "    url = f'https://www.booking.com/searchresults.en-gb.html?ss=New+York&ssne=New+York&ssne_untouched=New+York&lang=en-gb&dest_id=20088325&dest_type=city&checkin={checkin_date_str}&checkout={checkout_date_str}&group_adults=2&no_rooms=1&group_children=0&selected_currency=USD'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genius Modal closer\n",
    "There is a genius modal that sometimes pops up, and we need to close it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "\n",
    "def close_genius_modal(driver: webdriver.Chrome) -> bool:\n",
    "    try:\n",
    "        genius_modal_close_button = driver.find_element(By.XPATH, '//button[@aria-label=\"Dismiss sign in information.\"]')\n",
    "        genius_modal_close_button.click()\n",
    "        return True \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load More \n",
    "We are mimiccing a real user interaction by going up and down in the page with the `HOME` and `END` keys. when we cant load more results in this method, we click on the load more results button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "def load_more(driver: webdriver.Chrome) -> bool:\n",
    "    body = driver.find_element(By.TAG_NAME, 'body')\n",
    "    body.send_keys(Keys.HOME)\n",
    "    time.sleep(0.5)\n",
    "    body.send_keys(Keys.END)\n",
    "\n",
    "    try:\n",
    "        # Scroll down to attempt to load more results\n",
    "        driver.execute_script(\"window.scrollBy(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)  # Allow new elements to load\n",
    "        \n",
    "        # Find the 'Load more results' button\n",
    "        button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[span[contains(text(), 'Load more results')]]\"))\n",
    "        )\n",
    "        \n",
    "        # Scroll directly to the button before clicking (ensures visibility)\n",
    "        ActionChains(driver).move_to_element(button).perform()\n",
    "        button.click()\n",
    "        \n",
    "        return True  # Successfully clicked the button\n",
    "\n",
    "    except Exception:\n",
    "        return False  # No button found or unable to click\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimic a real-user's driver\n",
    "the Booking.com site can detect if a bot is trying to access it, and it will give it a different type of html, not the one you can see if you try to open the chrome devtools. In order to overcome this problem, and to be able to run the scraping in parrallel, we needed to define the driver in such way, that it will be headless and also behave like a user used site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "def init_driver(headless=True):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")  # Ensures modern headless mode\n",
    "        options.add_argument(\"--disable-gpu\")  # Fixes rendering issues\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    # ðŸš€ Make the browser appear more human-like\n",
    "    options.add_argument(\"--window-size=1920,1080\")  # Standard screen size\n",
    "    options.add_argument(\"--start-maximized\")  # Maximize on launch\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Prevent detection\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])  # Prevent 'bot' flag\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    \n",
    "    # Change User-Agent to a normal browser\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    # Remove webdriver property to avoid detection\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_hotels(driver: webdriver.Chrome, url: str) -> List[bs4.element.Tag]:\n",
    "    driver.get(url)\n",
    "\n",
    "    soup = None\n",
    "    hotels=[]\n",
    "    genius_modal_closed = False\n",
    "    previous_hotel_count = 0\n",
    "    while len(hotels) < 100:\n",
    "        if not genius_modal_closed:\n",
    "            time.sleep(6)\n",
    "            if close_genius_modal(driver):\n",
    "                genius_modal_closed = True\n",
    "\n",
    "        load_more(driver)\n",
    "            \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        hotels = soup.find_all('div', {'data-testid': \"property-card\"})\n",
    "        \n",
    "        if len(hotels) == previous_hotel_count:\n",
    "            print(\"No new hotels found\")\n",
    "            break\n",
    "        previous_hotel_count = len(hotels)\n",
    "        \n",
    "    return hotels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(hotel: bs4.element.Tag) -> Dict[str, str]:\n",
    "    return {\n",
    "        'name': hotel.find('div', {'data-testid': 'title'}).text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "def extract_price(hotel: bs4.element.Tag) -> Dict[str, Optional[int]]:\n",
    "    return {\n",
    "        'price': hotel.find('span', {'data-testid': 'price-and-discounted-price'}).text\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_info(hotel: bs4.element.Tag) -> Dict[str, str]:\n",
    "    rating_div = hotel.find('div', {'data-testid': 'review-score'})\n",
    "    if not rating_div:\n",
    "        return {\n",
    "            'review_score': None,\n",
    "            'review_title': None,\n",
    "            'number_of_reviews': None\n",
    "        }\n",
    "    review_divs = rating_div.find_all('div')\n",
    "    \n",
    "    return {\n",
    "        'review_score': review_divs[0].get_text(separator=':)', strip=True).split(':)')[1],\n",
    "        'review_title': review_divs[3].get_text(strip=True),\n",
    "        'number_of_reviews': review_divs[4].get_text(separator=' ', strip=True).split(' ')[0]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_star_rating(hotel: bs4.element.Tag) -> Dict[str, Optional[int]]:\n",
    "    star_rating_div = hotel.find('div', {'data-testid': 'rating-stars'})\n",
    "    if star_rating_div:\n",
    "        return {'star_rating': len(star_rating_div.find_all('svg'))}\n",
    "    else:\n",
    "        return {'star_rating': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_kms_from_centre(hotel: bs4.element.Tag) -> Dict[str, Optional[float]]:\n",
    "    distance_div = hotel.find('span', {'data-testid': 'distance'})\n",
    "    if  not distance_div:\n",
    "        return {'kms_from_centre': None}\n",
    "        \n",
    "    distance = distance_div.get_text(strip=True)\n",
    "    if not distance:\n",
    "        return {'kms_from_centre': None}\n",
    "        \n",
    "    from_centre = re.search(r'([\\d]+(?:\\.\\d+)?)\\s*km\\s+from\\s+centre', distance)\n",
    "    if not from_centre:\n",
    "        return {'kms_from_centre': None}\n",
    "\n",
    "    return {'kms_from_centre': float(from_centre.group(1))}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_score(hotel: bs4.element.Tag) -> Dict[str, Optional[float]]:\n",
    "    location_link = hotel.find('a', {'data-testid': 'secondary-review-score-link'})\n",
    "    \n",
    "    if not location_link:\n",
    "        return {'location_score': None}\n",
    "    \n",
    "    location_score_match = re.search(r'Scored\\s(\\d+\\.\\d+)', location_link['aria-label'])\n",
    "    \n",
    "    if not location_score_match:\n",
    "        return {'location_score': None}\n",
    "    \n",
    "    return {'location_score': float(location_score_match.group(1))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sleeping_arrangements(hotel: bs4.element.Tag) -> Dict[str, Optional[str]]:\n",
    "    recommended_units_div = hotel.find('div', {'data-testid': 'recommended-units'})\n",
    "    \n",
    "    sleeping_arrangements = {}\n",
    "    \n",
    "    sleeping_arrangements['room_type'] = (recommended_units_div and \n",
    "                               recommended_units_div.h4 and \n",
    "                               recommended_units_div.h4.get_text(strip=True)) or None\n",
    "    \n",
    "    sleeping_arrangements['bed_type'] = (recommended_units_div and \n",
    "                              recommended_units_div.ul and \n",
    "                              recommended_units_div.ul.li and \n",
    "                              recommended_units_div.ul.li.div and \n",
    "                              recommended_units_div.ul.li.div.div and \n",
    "                              recommended_units_div.ul.li.div.div.get_text(strip=True)) or None\n",
    "    \n",
    "    return sleeping_arrangements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_breakfast_included(hotel: bs4.element.Tag) -> Dict[str, bool]:\n",
    "    \n",
    "    if 'breakfast included' in hotel.get_text(strip=True).lower():\n",
    "        return {'breakfast_included': True}\n",
    "    else:\n",
    "        return {'breakfast_included': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_payment_policy(hotel: bs4.element.Tag) -> Dict[str, str]:\n",
    "    payment_policy = {}\n",
    "    \n",
    "    payment_policy['free_cancellation'] = True if hotel.find('span', {'data-testid': 'cancellation-policy-icon'}) else False\n",
    "    payment_policy['prepayment_needed'] = False if hotel.find('span', {'data-testid': 'prepayment-policy-icon'}) else True \n",
    "    \n",
    "    return payment_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hotel_info(hotel: bs4.element.Tag) -> Dict[str, Any]:\n",
    "    hotel_info = {}\n",
    "    \n",
    "    # basic info\n",
    "    extraction_functions = [\n",
    "        extract_name,\n",
    "        extract_price, \n",
    "        extract_review_info,\n",
    "        extract_star_rating,\n",
    "        extract_kms_from_centre,\n",
    "        extract_location_score,\n",
    "        extract_sleeping_arrangements,\n",
    "        extract_breakfast_included,\n",
    "        extract_payment_policy\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    for func in extraction_functions:\n",
    "        hotel_info.update(func(hotel))\n",
    "\n",
    "    return hotel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def get_hotels_dataframe(hotels: List[bs4.element.Tag]) -> pd.DataFrame:\n",
    "    hotels_info = [extract_hotel_info(hotel) for hotel in hotels]\n",
    "    return pd.DataFrame(hotels_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "\n",
    "SNAPSHOT_DATE = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "number_of_cores = os.cpu_count()\n",
    "max_workers = math.ceil(number_of_cores/3)\n",
    "\n",
    "\n",
    "def scrape_hotels_thread(TTT, LOS):\n",
    "    \"\"\"Scrape hotel data using a shared WebDriver with multiple tabs.\"\"\"\n",
    "    print(f'scraping TTT={TTT} / 30, LOS={LOS} / 5')\n",
    "    try:\n",
    "        url = build_url(TTT, LOS)\n",
    "\n",
    "        driver = init_driver(headless=True)  \n",
    "        # Open a new tab\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[-1])  # Switch to new tab\n",
    "        driver.get(url)\n",
    "\n",
    "        hotels = get_hotels(driver, url)\n",
    "        hotels_df = get_hotels_dataframe(hotels)\n",
    "        hotels_df['time_to_travel'] = TTT\n",
    "        hotels_df['length_of_stay'] = LOS\n",
    "        hotels_df['snapshot_date'] = SNAPSHOT_DATE\n",
    "\n",
    "        driver.close()  # Close tab after scraping\n",
    "        driver.switch_to.window(driver.window_handles[0])  # Switch back to main tab\n",
    "\n",
    "        return hotels_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping TTT={TTT}, LOS={LOS}: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame in case of failure\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "all_combinations = [(TTT, LOS) for TTT in range(1, 31) for LOS in range(1, 6)]\n",
    "\n",
    "# Run threads, each using a new tab in the same browser\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    results = list(executor.map(lambda args: scrape_hotels_thread(*args), all_combinations))\n",
    "    df = pd.concat(results, ignore_index=True)\n",
    "    df.to_csv(f'booking_snapshot_{SNAPSHOT_DATE}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-101-Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
